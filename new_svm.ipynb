{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data from the provided Excel file\n",
    "data_path = \"data.xlsx\"\n",
    "data_df = pd.read_excel(data_path)\n",
    "\n",
    "# Encode 'Jenis Kelamin' [Laki-laki = 0, Perempuan = 1]\n",
    "gender_encoder = LabelEncoder()\n",
    "data_df['Jenis Kelamin'] = gender_encoder.fit_transform(data_df['Jenis Kelamin'])\n",
    "\n",
    "# Encode 'Status Gizi' as the target variable for multi-class classification\n",
    "status_encoder = LabelEncoder()\n",
    "data_df['Status Gizi'] = status_encoder.fit_transform(data_df['Status Gizi'])\n",
    "\n",
    "# Store the original labels for later use\n",
    "original_labels = status_encoder.classes_\n",
    "\n",
    "# Filter the relevant columns for features and labels\n",
    "X = data_df[['Jenis Kelamin', 'Berat Badan Saat Lahir (kg)', 'Tinggi Badan Saat Lahir (cm)', \n",
    "             'Berat Badan Saat Ini (kg)', 'Tinggi Badan Saat Ini (cm)', 'Usia (bulan)', \n",
    "             'Z-Score Berat Badan', 'Z-Score Tinggi Badan']]\n",
    "y = data_df['Status Gizi']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create a pipeline that scales the features and then applies SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'svm__kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Use StratifiedKFold with n_splits=3 (or any number <= the smallest class size)\n",
    "cv_strategy = StratifiedKFold(n_splits=3)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=cv_strategy, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Ensure all original labels are included, even if they don't appear in the test set\n",
    "unique_labels = np.unique(np.concatenate([y_test, y_pred]))\n",
    "\n",
    "# Update the target names based on the unique labels\n",
    "actual_target_names = original_labels\n",
    "\n",
    "# Print the classification report\n",
    "classification_rep = classification_report(y_test, y_pred, labels=unique_labels, target_names=actual_target_names)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "\n",
    "# Print results\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "print(f\"\\nTest accuracy: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_rep)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=actual_target_names, yticklabels=actual_target_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.close()\n",
    "\n",
    "# Save the best model and encoders to a file using pickle\n",
    "model_path = \"svm_model.pkl\"\n",
    "with open(model_path, 'wb') as model_file:\n",
    "    pickle.dump({\n",
    "        'model': best_model,\n",
    "        'gender_encoder': gender_encoder,\n",
    "        'status_encoder': status_encoder\n",
    "    }, model_file)\n",
    "\n",
    "print(f\"\\nBest model and encoders have been saved to {model_path}\")\n",
    "\n",
    "# Feature importance (for SVM, we'll use the absolute values of the coefficients for linear kernel)\n",
    "if best_model.named_steps['svm'].kernel == 'linear':\n",
    "    feature_importance = np.abs(best_model.named_steps['svm'].coef_[0])\n",
    "    feature_names = X.columns\n",
    "    feature_importance_dict = dict(zip(feature_names, feature_importance))\n",
    "    sorted_features = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    for feature, importance in sorted_features:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(feature_names, feature_importance)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png')\n",
    "    plt.close()\n",
    "else:\n",
    "    print(\"\\nFeature importance is not available for non-linear kernels.\")\n",
    "\n",
    "print(\"\\nTraining and evaluation completed. Check the output files for detailed results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "\n",
    "# Define function to calculate Z-score\n",
    "def calculate_z_score(value, mean, std_dev):\n",
    "    return (value - mean) / std_dev\n",
    "\n",
    "# Function to classify Z-score for height\n",
    "def classify_z_score_height(z_score):\n",
    "    if z_score < -3:\n",
    "        return \"Sangat Pendek\"\n",
    "    elif -3 <= z_score < -2:\n",
    "        return \"Pendek\"\n",
    "    elif -2 <= z_score <= 2:\n",
    "        return \"Normal\"\n",
    "    else:\n",
    "        return \"Tinggi\"\n",
    "\n",
    "# Function to classify Z-score for weight\n",
    "def classify_z_score_weight(z_score):\n",
    "    if z_score < -3:\n",
    "        return \"Gizi Buruk\"\n",
    "    elif -3 <= z_score < -2:\n",
    "        return \"Gizi Kurang\"\n",
    "    elif -2 <= z_score <= 1:\n",
    "        return \"Gizi Baik\"\n",
    "    elif 1 < z_score <= 2:\n",
    "        return \"Berpotensi Berlebihan\"\n",
    "    elif 2 < z_score <= 3:\n",
    "        return \"Gizi Lebih\"\n",
    "    else:\n",
    "        return \"Obesitas\"\n",
    "\n",
    "# Function to generate dummy data with the specified columns\n",
    "def generate_modified_dummy_data(num_samples):\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "\n",
    "    # Generate age and height data\n",
    "    ages = np.random.randint(0, 60, size=num_samples)\n",
    "    mean_height = [49.9, 54.7, 58.4, 61.4, 63.9, 65.9, 67.6, 68.6, 69.6, 70.6, 71.6, 72.6, 73.6, 74.6, 75.6, 76.6, 77.6, 78.6, 79.6, 80.6, 81.6, 82.6, 83.6, 84.6, 85.6, 86.6, 87.6, 88.6, 89.6, 90.6, 91.6, 92.6, 93.6, 94.6, 95.6, 96.6, 97.6, 98.6, 99.6, 100.6, 101.6, 102.6, 103.6, 104.6, 105.6, 106.6, 107.6, 108.6, 109.6, 110.6, 111.6, 112.6, 113.6, 114.6, 115.6, 116.6, 117.6, 118.6, 119.6, 120.6, 121.6, 122.6]\n",
    "    std_dev_height = [3.8, 4.4, 4.9, 5.3, 5.6, 5.9, 6.2, 6.4, 6.7, 6.9, 7.1, 7.3, 7.5, 7.7, 7.9, 8.1, 8.3, 8.5, 8.7, 8.9, 9.1, 9.3, 9.5, 9.7, 9.9, 10.1, 10.3, 10.5, 10.7, 10.9, 11.1, 11.3, 11.5, 11.7, 11.9, 12.1, 12.3, 12.5, 12.7, 12.9, 13.1, 13.3, 13.5, 13.7, 13.9, 14.1, 14.3, 14.5, 14.7, 14.9, 15.1, 15.3, 15.5, 15.7, 15.9, 16.1, 16.3, 16.5, 16.7, 16.9, 17.1, 17.3]\n",
    "\n",
    "    mean_weight = [3.3, 4.5, 5.6, 6.4, 7.0, 7.5, 7.9, 8.3, 8.6, 8.9, 9.2, 9.4, 9.6, 9.9, 10.1, 10.3, 10.5, 10.7, 10.9, 11.1, 11.3, 11.5, 11.7, 11.9, 12.2, 12.4, 12.5, 12.7, 12.9, 13.1, 13.3, 13.5, 13.7, 13.9, 14.1, 14.3, 14.5, 14.7, 14.9, 15.1, 15.3, 15.5, 15.7, 15.9, 16.1, 16.3, 16.5, 16.7, 16.9, 17.1, 17.3, 17.5, 17.7, 17.9, 18.1, 18.3, 18.5, 18.7, 18.9, 19.1, 19.3, 19.5]\n",
    "    std_dev_weight = [0.5, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2.0, 2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.9, 3.0, 3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4.0, 4.1, 4.2, 4.3, 4.4, 4.5, 4.6, 4.7, 4.8, 4.9, 5.0, 5.1, 5.2, 5.3, 5.4, 5.5, 5.6, 5.7, 5.8, 5.9, 6.0, 6.1, 6.2, 6.3, 6.4, 6.5, 6.6, 6.7]\n",
    "\n",
    "    # Generate weight data with variations for underweight\n",
    "    weights = []\n",
    "    for age in ages:\n",
    "        if np.random.rand() > 0.43:  # 30% chance of underweight\n",
    "            weight = np.random.normal(mean_weight[age] - 1.5 * std_dev_weight[age], std_dev_weight[age])\n",
    "        else:\n",
    "            weight = np.random.normal(mean_weight[age], std_dev_weight[age])\n",
    "        weights.append(weight)\n",
    "\n",
    "    # Generate height data\n",
    "    heights = [np.random.normal(mean_height[age], std_dev_height[age]) for age in ages]\n",
    "\n",
    "    # Calculate Z-scores for height and weight\n",
    "    z_scores_height = [calculate_z_score(height, mean_height[age], std_dev_height[age]) for height, age in zip(heights, ages)]\n",
    "    z_scores_weight = [calculate_z_score(weight, mean_weight[age], std_dev_weight[age]) for weight, age in zip(weights, ages)]\n",
    "\n",
    "    # Generate gender data\n",
    "    genders = np.random.choice(['Laki-laki', 'Perempuan'], num_samples)\n",
    "\n",
    "    # Generate birth weight and height data\n",
    "    birth_weights = np.random.normal(3.5, 0.5, num_samples)\n",
    "    birth_heights = np.random.normal(50, 2, num_samples)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        \"Nama\": [f'Child_{i+1}' for i in range(num_samples)],\n",
    "        \"Jenis Kelamin\": genders,\n",
    "        \"Berat Badan Saat Lahir (kg)\": birth_weights,\n",
    "        \"Tinggi Badan Saat Lahir (cm)\": birth_heights,\n",
    "        \"Berat Badan Saat Ini (kg)\": weights,\n",
    "        \"Tinggi Badan Saat Ini (cm)\": heights,\n",
    "        \"Usia (bulan)\": ages,\n",
    "        \"Z-Score Berat Badan\": z_scores_weight,\n",
    "        \"Z-Score Tinggi Badan\": z_scores_height,\n",
    "        \"Klasifikasi Z score-TB\": [classify_z_score_height(z) for z in z_scores_height],\n",
    "        \"Klasifikasi Z score-BB\": [classify_z_score_weight(z) for z in z_scores_weight]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Drop 'Status Gizi' to simulate test data where we don't know the actual nutritional status\n",
    "    return df\n",
    "\n",
    "# Function to validate predictions\n",
    "def validate_predictions(predictions, valid_classes):\n",
    "    invalid_indices = np.where(~np.isin(predictions, valid_classes))[0]\n",
    "    if len(invalid_indices) > 0:\n",
    "        print(f\"Warning: Found {len(invalid_indices)} invalid predictions.\")\n",
    "        predictions[invalid_indices] = np.random.choice(valid_classes)  # Replace with a random valid class\n",
    "    return predictions\n",
    "\n",
    "# Define valid classes\n",
    "valid_classes = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# Load the saved model and scaler\n",
    "# Load the saved model and scaler\n",
    "model_path = \"svm_model.pkl\"\n",
    "scaler_path = \"scaler.pkl\"\n",
    "with open(model_path, 'rb') as model_file, open(scaler_path, 'rb') as scaler_file:\n",
    "    saved_data = pickle.load(model_file)  # Load the dictionary\n",
    "    model = saved_data['model']  # Access the model from the dictionary\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Generate the testing data\n",
    "test_data_df = generate_modified_dummy_data(200)  # Generate 20 samples for testing\n",
    "\n",
    "# Display the testing data\n",
    "display(test_data_df)\n",
    "\n",
    "# Encode 'Jenis Kelamin' [Laki-laki = 0, Perempuan = 1] using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "test_data_df['Jenis Kelamin'] = label_encoder.fit_transform(test_data_df['Jenis Kelamin'])\n",
    "\n",
    "# Preprocess the testing data in the same way as the training data\n",
    "test_X = test_data_df[['Jenis Kelamin', 'Berat Badan Saat Lahir (kg)', \n",
    "                       'Tinggi Badan Saat Lahir (cm)', 'Berat Badan Saat Ini (kg)', \n",
    "                       'Tinggi Badan Saat Ini (cm)', 'Usia (bulan)', \n",
    "                       'Z-Score Berat Badan', 'Z-Score Tinggi Badan']].values\n",
    "\n",
    "# Transform the test data using the same scaler used during training\n",
    "test_X = scaler.transform(test_X)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "test_predictions = model.predict(test_X)\n",
    "\n",
    "# Convert predictions to integer type\n",
    "test_predictions = test_predictions.astype(int)\n",
    "\n",
    "\n",
    "# Validate predictions to ensure they only contain valid classes\n",
    "test_predictions = validate_predictions(test_predictions, valid_classes)\n",
    "\n",
    "# Specify the actual class names\n",
    "label_encoder.classes_ = np.array(['Gizi Buruk', 'Gizi Kurang', 'Gizi Baik', 'Gizi Lebih', 'Obesitas'])\n",
    "\n",
    "# Map predictions back to class labels\n",
    "test_data_df['Prediksi Status Gizi'] = label_encoder.inverse_transform(test_predictions)\n",
    "\n",
    "# Display the prediction results\n",
    "display(test_data_df)\n",
    "\n",
    "# Save the predictions to a new Excel file\n",
    "test_data_df.to_excel('prediksi_status_gizi.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Setelah melakukan prediksi pada data uji\n",
    "# Kita asumsikan `y_pred` adalah hasil prediksi dan `y_test` adalah label asli dari data uji\n",
    "\n",
    "# Gabungkan hasil prediksi dengan data uji asli\n",
    "test_results_df = X_test.copy()\n",
    "test_results_df['Actual Status Gizi'] = status_encoder.inverse_transform(y_test)\n",
    "test_results_df['Predicted Status Gizi'] = status_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Definisikan rentang usia\n",
    "age_bins = [0, 12, 24, 36, 48, 60]\n",
    "age_labels = ['0-12 bulan', '13-24 bulan', '25-36 bulan', '37-48 bulan', '49-60 bulan']\n",
    "\n",
    "# Tambahkan kolom grup usia\n",
    "test_results_df['Age Group'] = pd.cut(test_results_df['Usia (bulan)'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# Hitung frekuensi persentase berdasarkan grup usia dan status gizi yang diprediksi\n",
    "status_gizi_distribution = test_results_df.groupby(['Age Group', 'Predicted Status Gizi']).size().reset_index(name='count')\n",
    "status_gizi_distribution['percentage'] = status_gizi_distribution.groupby('Age Group')['count'].transform(lambda x: x / x.sum() * 100)\n",
    "\n",
    "# Buat grafik menggunakan Plotly\n",
    "fig = px.bar(status_gizi_distribution, \n",
    "             x='Age Group', \n",
    "             y='percentage', \n",
    "             color='Predicted Status Gizi', \n",
    "             barmode='group',\n",
    "             labels={'percentage': 'Percentage', 'Age Group': 'Age Group (Months)', 'Predicted Status Gizi': 'Nutritional Status'},\n",
    "             title='Percentage Distribution of Predicted Nutritional Status by Age Group')\n",
    "\n",
    "# Tampilkan grafik\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Persiapkan data untuk visualisasi\n",
    "train_dist = pd.DataFrame({\n",
    "    'Status Gizi': status_encoder.inverse_transform(y_train),\n",
    "    'Jenis Kelamin': gender_encoder.inverse_transform(X_train['Jenis Kelamin'])\n",
    "})\n",
    "\n",
    "test_dist = pd.DataFrame({\n",
    "    'Status Gizi': status_encoder.inverse_transform(y_test),\n",
    "    'Jenis Kelamin': gender_encoder.inverse_transform(X_test['Jenis Kelamin'])\n",
    "})\n",
    "\n",
    "pred_dist = pd.DataFrame({\n",
    "    'Predicted Status Gizi': status_encoder.inverse_transform(y_pred),\n",
    "    'Jenis Kelamin': gender_encoder.inverse_transform(X_test['Jenis Kelamin'])\n",
    "})\n",
    "\n",
    "# Buat subplots\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    subplot_titles=(\"Training Data Distribution by Gender\", \"Test Data Distribution by Gender\", \"Predicted Data Distribution by Gender\"),\n",
    "    shared_xaxes=True\n",
    ")\n",
    "\n",
    "# Plot distribusi data pelatihan\n",
    "train_fig = px.histogram(train_dist, \n",
    "                         x='Status Gizi', \n",
    "                         color='Jenis Kelamin', \n",
    "                         barmode='group',\n",
    "                         color_discrete_map={'Laki-laki': 'blue', 'Perempuan': 'pink'})\n",
    "\n",
    "# Plot distribusi data uji\n",
    "test_fig = px.histogram(test_dist, \n",
    "                        x='Status Gizi', \n",
    "                        color='Jenis Kelamin', \n",
    "                        barmode='group',\n",
    "                        color_discrete_map={'Laki-laki': 'blue', 'Perempuan': 'pink'})\n",
    "\n",
    "# Plot distribusi hasil prediksi\n",
    "pred_fig = px.histogram(pred_dist, \n",
    "                        x='Predicted Status Gizi', \n",
    "                        color='Jenis Kelamin', \n",
    "                        barmode='group',\n",
    "                        color_discrete_map={'Laki-laki': 'blue', 'Perempuan': 'pink'})\n",
    "\n",
    "# Menambahkan plot ke subplots\n",
    "for trace in train_fig['data']:\n",
    "    fig.add_trace(trace, row=1, col=1)\n",
    "\n",
    "for trace in test_fig['data']:\n",
    "    fig.add_trace(trace, row=2, col=1)\n",
    "\n",
    "for trace in pred_fig['data']:\n",
    "    fig.add_trace(trace, row=3, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=900, width=700, title_text=\"Distribution of Nutritional Status by Gender\",\n",
    "                  xaxis_title=\"Status Gizi\", yaxis_title=\"Count\")\n",
    "\n",
    "# Tampilkan grafik\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Misalkan kita menggunakan seluruh fitur untuk t-SNE\n",
    "X = data_df[['Jenis Kelamin', 'Berat Badan Saat Lahir (kg)', 'Tinggi Badan Saat Lahir (cm)', \n",
    "             'Berat Badan Saat Ini (kg)', 'Tinggi Badan Saat Ini (cm)', 'Usia (bulan)', \n",
    "             'Z-Score Berat Badan', 'Z-Score Tinggi Badan']].values\n",
    "\n",
    "y = data_df['Status Gizi']\n",
    "\n",
    "# Normalisasi data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Terapkan t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "# Buat DataFrame untuk visualisasi\n",
    "tsne_df = pd.DataFrame(data=X_tsne, columns=['t-SNE 1', 't-SNE 2'])\n",
    "\n",
    "# Terapkan inverse transform untuk mendapatkan label asli\n",
    "tsne_df['Status Gizi'] = status_encoder.inverse_transform(y)\n",
    "\n",
    "# Visualisasi dengan Plotly\n",
    "fig = px.scatter(tsne_df, x='t-SNE 1', y='t-SNE 2', color='Status Gizi',\n",
    "                 title='t-SNE Visualization of Nutritional Status',\n",
    "                 labels={'color': 'Status Gizi'})\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
